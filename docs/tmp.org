autoregressive decoding with predicted images works well,
which means that the decoder output does not have to be a random variable at all.
if so, there is no need for an autoregressive model either.
we could try a fully convolutional network:
- convolutional encoder to produce the annotations
- transposed convolution for constructing the decoder outputs

the same architecture with one-hot characters (the baseline) may work much better,
with the output being a discrete random variable and the autoregressive structure and what not.
if so, we may think about how to improve the image-based model without drastically changing the architecture.
(it would not be fair to use a larger model to beat the baseline.)
the option i could think of is to use the idea of iterative refinement.
- run the same decoder on its own outputs again, teacher-forcing style
- take both predictions for computing the loss
